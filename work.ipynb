{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGZCAYAAABmNy2oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/10lEQVR4nO2deZidVZX1952HurfGpFJJKqMJiUmAJCikCV8nJECEgA2KRLRNGLt9BKVVULERWlDRtsVu/DDBR0mgaQYZFCR8qAxiBEQiZJ7ITFIZaq5bw53f7w+aI+VZO95D3SJB1+95+CMrJ+c973R3Xc6qtX2e53lCCCGEiIj/aC+AEELIsQOLAiGEEAOLAiGEEAOLAiGEEAOLAiGEEAOLAiGEEAOLAiGEEAOLAiGEEAOLAiGEEAOLAvmLrFixQnw+n6xevfpoL0V2794tPp9PVqxYUbY53zq/3bt3H3Hcv/3bv4nP55OWlpayHZuQYw0WBUIIIQYWBUIIIQYWBVI2fve738n8+fMlmUxKPB6XU089VVauXNlvTHNzs3zmM5+RKVOmSCKRkPr6epk3b56sWrXKmq+pqUkuuugiSSaTUlVVJYsWLZKDBw/CY69evVo+/OEPS21trUSjUZkxY4b89Kc/tcb9/ve/l9mzZ0s0GpURI0bI9ddfL7lc7h2f89y5c2XatGny0ksvyamnniqxWEzGjh0ry5cvFxGRlStXysyZMyUej8vxxx8vTz31VL9/v337drn00ktl4sSJEo/HZeTIkXLeeefJ+vXrrWNt3LhRzjrrLInH4zJ06FC56qqrZOXKleLz+eQ3v/lNv7FPP/20zJ8/XyorKyUej8vs2bPlmWeeecfnSf52YFEgZeH555+XefPmSWdnp/zkJz+R+++/X5LJpJx33nny4IMPmnFtbW0iInLTTTfJypUrZfny5TJ+/HiZO3duvw+2vr4+OeOMM+RXv/qV3HrrrfLQQw9JQ0ODLFq0yDr2c889J7Nnz5aOjg5ZtmyZPPbYYzJ9+nRZtGhRv72HTZs2yfz586Wjo0NWrFghy5Ytk9dee02+8Y1vDOjcDx48KJdeeqlcccUV8thjj8nxxx8vl112mdx8881y/fXXy5e+9CV55JFHJJFIyPnnny9NTU3m3zY1NUldXZ18+9vflqeeekruuOMOCQaDcsopp8jWrVvNuAMHDsicOXNk69atsnTpUrnnnnsklUrJ1Vdfba3n3nvvlbPOOksqKyvl7rvvlp/+9KdSW1srCxYsYGEgfxmPkL/A8uXLPRHxXnnlFXXMrFmzvPr6ei+VShktn89706ZN8xobG71isQj/XT6f93K5nDd//nzvggsuMPrSpUs9EfEee+yxfuOvvPJKT0S85cuXG23y5MnejBkzvFwu12/sueee6w0fPtwrFAqe53neokWLvFgs5h08eLDf8SdPnuyJiLdr164jXoebbrrJExGvubnZaHPmzPFExFu9erXRWltbvUAg4MViMW///v1GX7NmjSci3u23364eI5/Pe9ls1ps4caL3+c9/3ujXXXed5/P5vI0bN/Ybv2DBAk9EvOeee87zPM/r6enxamtrvfPOO6/fuEKh4J144oneySeffMRzJITfFMiA6enpkZdfflkuvPBCSSQSRg8EAvKpT31K9u3b1++n3mXLlsnMmTMlGo1KMBiUUCgkzzzzjGzevNmMee655ySZTMqHP/zhfsf6xCc+0e/P27dvly1btsgnP/lJERHJ5/Pmv3POOUcOHDhgjv3cc8/J/PnzZdiwYf3WiL59uDB8+HA56aSTzJ9ra2ulvr5epk+fLiNGjDD6+9//fhER2bNnj9Hy+bx861vfkilTpkg4HJZgMCjhcFhef/31ftfj+eefl2nTpsmUKVP6Hfviiy/u9+cXX3xR2traZMmSJf2uRbFYlA996EPyyiuvSE9Pz4DOl/x1EzzaCyDvfdrb28XzPBk+fLj1d299KLa2toqIyG233SZf/OIX5dOf/rTccsstMmTIEAkEAvK1r32t34dga2trvw/vt2hoaOj350OHDomIyLXXXivXXnstXN9bFtLW1lbr36M5XamtrbW0cDhs6eFwWERE0um00b7whS/IHXfcIV/+8pdlzpw5UlNTI36/X6644grp6+sz41pbW2XcuHHWcf78Gr11PS688EJ1vW1tbVJRUVHCmZG/RVgUyIB564PswIED1t+99f/PhwwZIiJv/v/uuXPnytKlS/uNS6VS/f5cV1cnf/jDH6z5/nyj+a15r7/+evnIRz4C1zdp0iQzJ9qo1jav3w3uvfdeWbx4sXzrW9/qp7e0tEh1dbX5c11dnfnAfzva9fjBD34gs2bNgsdExZaQt+D/PiIDpqKiQk455RR59NFH+/10WywW5d5775XGxkY57rjjRETE5/NJJBLp9+/XrVsnL730Uj/t9NNPl1QqJY8//ng//b777uv350mTJsnEiRNl7dq18oEPfAD+l0wmzZzPPPNMvw/XQqHQbyP83QZdj5UrV8r+/fv7aXPmzJENGzbIpk2b+ukPPPBAvz/Pnj1bqqurZdOmTer1eOsbCyEIflMgJfPss8/C3/o955xz5NZbb5UzzzxTTj/9dLn22mslHA7LD3/4Q9mwYYPcf//94vP5RETk3HPPlVtuuUVuuukm46a5+eabZdy4cZLP582cixcvlu9///uyePFi+eY3vykTJ06UJ598Un75y19ax7/zzjvl7LPPlgULFsgll1wiI0eOlLa2Ntm8ebO8+uqr8tBDD4mIyA033CCPP/64zJs3T2688UaJx+Nyxx13HNX/x37uuefKihUrZPLkyXLCCSfIH//4R/nud78rjY2N/cb9y7/8i9x1111y9tlny8033yzDhg2T++67T7Zs2SIiIn7/mz/fJRIJ+cEPfiBLliyRtrY2ufDCC6W+vl6am5tl7dq10tzcbH1LI6QfR3unmxz7vOU+0v57y7WzatUqb968eV5FRYUXi8W8WbNmeb/4xS/6zZXJZLxrr73WGzlypBeNRr2ZM2d6P//5z70lS5Z4Y8aM6Td237593kc/+lEvkUh4yWTS++hHP+q9+OKLlvvI8zxv7dq13kUXXeTV19d7oVDIa2ho8ObNm+ctW7as37gXXnjBmzVrlheJRLyGhgbvuuuu8370ox8NyH00depUa+yYMWO8hQsXWrqIeFdddZX5c3t7u3f55Zd79fX1Xjwe90477TRv1apV3pw5c7w5c+b0+7cbNmzwzjjjDC8ajXq1tbXe5Zdf7t19992eiHhr167tN/b555/3Fi5c6NXW1nqhUMgbOXKkt3DhQu+hhx464jkS4vM8zzs65YgQMlD+6Z/+Se6//35pbW3l/xYiZYH/+4iQ9wg333yzjBgxQsaPHy/d3d3yxBNPyI9//GO54YYbWBBI2WBRIOQ9QigUku9+97uyb98+yefzMnHiRLntttvkmmuuOdpLI39F8H8fEUIIMdCSSgghxMCiQAghxMCiQAghxFDyRvMFF1wA9a1bN0N97949lqY5JIrFItT9/oDTeMT//s7UoODz4ZqqHbNYxNs3waB9noVCAY5VN4C0v1DW4nRZlLl9freLe6xvX2nL0+5nIGC/PoVCHozU5z7CHUUrcRjrOvdgzXCkiQb3eUDX/K1f8it1LfpnTen3wtPOU33e8Nyo70d9fT0cO2PGSVD/2c9+hg/6NvhNgRBCiIFFgRBCiIFFgRBCiIFFgRBCiIFFgRBCiGHAv9H8ne/gpudLl95uaXV1Q+BYbYf/7R2q3k48Hre0YBAbqd4ex/x2AgHsbNJ2/pGezWbg2KLiHIpEo1D/8wYzIqJ2xgqFQlDX0BxSyCXjek2QG0JExKc4MwJBtBY3R43m4EJr1FxD2jOhXVttfGdnp6W9vR3p2wkqc2vXCp1lPpeFY/3ABfXm3BjtffMBZ46nuW+Ui5tXngk/erYc3Tf5PJ5bW0sAnE+3FpOufAzG4vg99Dx8XdCzon02ubouu8DzduZZH4Jj71x2F9RLgd8UCCGEGFgUCCGEGFgUCCGEGFgUCCGEGFgUCCGEGErOPtJMSn19fVBvaBhtaaNGjYFj9+zZAfUPfvBUqG/auN7SWlsPw7H19Q1Qz+Y05xB2BOSA82H0qHFwbHVNLdR37sTn+alPXWlpTz75OBx7+NABqPsDuL7nsvj+VFZVW5rWwD6dxnNMnnw81AvKNdy7dzvUEZozIx6PQR05oTIZ7NapramD+v6mfVCvq8X5Mldf/UVLe/jhB/Hc+/HcfiU/CuVhDRkyFI5FLigR/Z3V8n8ymV5L0xxZ2v2pAs+ViEhnZwfUEdksvm811TVQzyguwK4u29U3fcYH4FjtWq1b+yrUNadevMJ2n7W2NMOxMeCiFBHxitjtlkp1W1ohj++Ddj6as+vt8JsCIYQQA4sCIYQQA4sCIYQQA4sCIYQQQ8kbzdoGRV8v3oQ855xzLe3kk2fBsf9z739D/Uc/wr+qvWjRRZb2letvhGMPH8Yb0L299qaaiMijjz4A9X379lraJ//xUjh27tx5UL/sskugfvXVn7O0vj4c8XHWWQug/q1vfh3qZ5+zEOqxmP3r+2PGjIVjtSiTj33s41Dv6uqC+kZgEFiy5DI49plnnob63SvuhPqQofZm8K233qysYxPUYzEcQ/LQQz+F+lVX2fctlcLP1VlnnQX1z3zmn6H+iYs/aWk+Jf7ggx/Em6df/zp+Jz71qSVQHz3aNoLceecyOPbkD54M9YAS6TBzpt305cYbvwrHnn/+R6CeTFZBvaICb9j++Mc/srR//epNcKwWqXPDDddD/av/+jWo799nGwqi0Qgce+edS6H+ve/9F9Rfe+01oP0Rji1lQ1mD3xQIIYQYWBQIIYQYWBQIIYQYWBQIIYQYWBQIIYQYSnYfaRSKuKFM48iRlnb88TgWoa29xemYHWC8FiExfLi9DhGRqNLwJg5cOSIiPtARpKOjHY5NpbD7JpPGMRKoccyGDbZTR0TkC1+woxVERMaMfR/UP/KRj0H9kUcetrQ9e/bAsbVKzMO4cTjmo70dXxfkSpo6dRoc+4XPfxbqLS147smTT7C0+fPPgGO/ev2XoD7puOOgHlfcIyhaY+sW7Gz6yle+AvXJyjFRFEVrWxscq7n6JkzAc5944gyot7ba79Wrr/4Bjj3zTOyC2717F9RPOeUUS5s6FX8eLFp0MdQ1t87q1XiNKIJHi9s4ePAg1E88cTrUT597OtS/+MUvWNpcZeywYcOhfsIJ9rMsIvL9//wPSytojYcGAL8pEEIIMbAoEEIIMbAoEEIIMbAoEEIIMbAoEEIIMQzYfRQM4CkON9uNJd544w04Vmvu0tTUBPWGhhGWpmUZHTiA5zh34XlQf+qpJ6Ae3GU3Gzl4ADe80dYSjyehvm+ffV3ywNkiIrJjB3ZZtbe3Qv3ZZ3GGEGrCoWXIdHVhx8/BA9ix0daOXTJdoBnM2rVr4NjNm7GLR8t02QJcP2vXroVjL774H6E+fDh2g6xY/mOoI8eK1iBm+3bcYCiVshvBiIicdtr/sbQnn3wSjl23Dp9nT7fdlEVEZP/+/VBfu26NpfX24nfztNNOg/revXZGmIjIunXrLE0795UrfwH1CRMmQl1zsN11l33ftm3bBseOHm03BRPRz+fVV3Hznfp626mnuRE1l94B5XPltVftnKPp00+EYwcCvykQQggxsCgQQggxsCgQQggxsCgQQggxsCgQQggx+DxkQ3Hg29++Ber/fc8KS0M78yK6W0frhBUM2k6gopLBVFc3BOotLThvqVDArp9wOGxpuVwejo3FsYsnr4z3+21HDcrVEREJgXWIiOSVDJSc4oYZPqLR0tJp3EWvQ3ETRaMxqKMsJxGRNOjSl83ja9KtOGe0jnQZsPaEch9GglwuEZF9b+Dsp0w6A/WKRMLSshk8Nq48y319yrMP1h6Lac8VvsdesQj1sJL7lcnb4/0h7C5MVGAnndZ5LQOuS0G599pzOHLkKKj3Ktewvc125AUUtyS6lyIiKaWLYFC5Lg0NtoNtH+jGJiJSKODzj8dx/lpLi+3oPOMM3NHvzjtx18pS4DcFQgghBhYFQgghBhYFQgghBhYFQgghhgHHXPh9uK6gpjTForIxqzQx0TbK0MYaakoiInLoEP6V8WDI3qwWEYkG8SYcHKusu6hs+gYCpdfgSARvKBeVaxJSNvjCITxPS8shS/P7A3BsRQXe+MoX8Oa+dt8KYANa2zjW7qduPrDPX2tAsnfXTqhHlWteCOLr0gliO7QYjr40Ps9IGD+HObTZqpxPMIDX16cYG1KKsSMcsZ/nYhavL6y8Px7eZxd0WbRrFVfiVg4exJE1PmDUEMGNtArKs9mtRFEElXuvvYe7d9vPVkh5B7W5Mxn8rLxb8JsCIYQQA4sCIYQQA4sCIYQQA4sCIYQQA4sCIYQQw4DdR4I3/sUPnDZaQ56ih3fyAz68O+8DzhTFyCAhxd3h0xauyeAAmnvCpziBtMnhNFr4CL4kUlTTSrAejaCICrc5NAdKRzdunpIGDhzNgaH9vJJJ40iHOHCajGjAsQjDh9ZBfeduHHOxbftuqKsPCwC5o0R0N0y+aJ9/VHl/NPeNp8SN5EGchYiI32+7lcJRfI9FcR0Gg1jHa8HrU5YtEeCOEsENo96cxz5P7Z1F0TlHmtuvzBOJ2M+hdh+0uQOKmwwdsfQnsHT4TYEQQoiBRYEQQoiBRYEQQoiBRYEQQoiBRYEQQohhwO4jbTcfZSJpeTY+T3HlKOPRzr/mwFAdQmXQnR1MqvsIOZvwHJo/yK84GdQeSkh2tDIUtewj5ZioQVBGyQTq7cONVrJKns/kCeMsbfoJU+FYlFkkIpLP4/OJxbDrpRfkNsWUBjYB5YZqjZq6e+y5tdujZTb19ClBRMp7hc5SmzvokOMlIvCB9rT33ofdUdrDr70T8H1Tn3G3XmOOZj+M60v+LvmP+E2BEEKIgUWBEEKIgUWBEEKIgUWBEEKIgUWBEEKIYfDcR8DhoLmPVEeN4ihCzqayuY+cHEKOO/8uuUqOziYNPXdFcXigsYqu3c+qJO7Udri51dLSGZxlpOladzjkVNvfhLvurXltPT5mFh9Tu+i5gn0NPSUTKKBkPPWmsUMIObjyilMpEHXr7JUt4DuaAB3Pwq7ZYepzC46pWniULCflSdTW4mKwc/MeOf6Lch0Utq9znKME+E2BEEKIgUWBEEKIgUWBEEKIgUWBEEKIgUWBEEKIYeDuI2X7G2cfaV22lO5GSr4KnFtxfaid4TT3kYOLSXcIuVoC7PPXnU1uc3tKjkwR5c4obgitq1tMcaYUunuw3tdraZWKc+bUU06COnIwiYiMGd1oafEYziGqTO6Ceqa5GerFHHYlJcL261PM4iynTA4/n1p+FHIO1VQm4Fi/cuMah1TjtSjuI/ROJJXcpz5shBIlzgj/RZlcOeobgR5x5VkumysJdlF0/TxwGc/sI0IIIYMIiwIhhBADiwIhhBADiwIhhBBDGWIuFB1s2GqxFT6lNmkxCjBCw3njWGn4o+7vlh5zoUdl4Kmd+nI4RgCojUxA/IUaI6AsUGt4Ew3hDeiuVLel+XvwfThu3GioT540EeqHDrdY2qgxY+DYpn37od7W3g51UTaaA+AZCijmiHweb/iHQeMhEZHGodWW1t2DGw/llOZAEWUttdVVUO9J2+fpgSgPEZFgEN/jnLKJ7XOKhXA0Uzh039H3wR1fTqedabfNbRcGIeWC3xQIIYT8CRYFQgghBhYFQgghBhYFQgghBhYFQgghhgG7j7T9b+w+0hw/eI6Ag/vI1WWkOqEcmvKoURSqKwnj3uADTaK5j5ThwFKkNd7R5sCeF5GahnqofwBEN+w/cBCOXfW730N9wTlnQT2bsZ05rc2H4dhAED/20ZjdZEZEpA+4ckREcnlb15xA2jMRCuG1tHfZUSH7Wzrg2IoojqIoFPH9TOXxDa2tAa4kJZpG6d2kvhPQIaTNgeUj/g0+psNYh6ZTR1oJelc09566vvL013rH8JsCIYQQA4sCIYQQA4sCIYQQA4sCIYQQA4sCIYQQw6BlH6EsIs2ZoOUWuWQfuTTHOdJ4rVmPi/tIb76D5XKgORmKigMF/gNP+RlBsR+h7B8RkY5uu5mOiMgI0AinoWEoHPvyaxugrrnJxo4ba2l79+yFY9OZDNSDSg6Rdp9RzE8sFoNj80ozne40Xkt7t+2mCitNjbSXsCenNPCRHNQLHXY2VXUNvt6hCHZqOYUFuVh43gGw34061jVTrPR1OJ/NYM5dAvymQAghxMCiQAghxMCiQAghxMCiQAghxMCiQAghxFCG7CMNB7eOc9c0B2eTY96SrgPHkxp95GgzcrFJOKKdvwdcSW7pL6KuMRDEx9y4baelHT5kd0wTEVkw7zSow3weEcmALnB7du/BYzNpqMdjUagnEhVQH1E5zNKqqvD6Xl2/CepFJUQoDHKiXJxxIiKhAM4tqojhrKQceCZ609ipVB1VnnEtFMkBbQbVCaTqA6cceWXax4GaH6UdczCsRgB+UyCEEGJgUSCEEGJgUSCEEGJgUSCEEGIYxI3mQQT+xryyPaM2mSl5anUi9ZgKThvQWmcO9Twdd6HQZr3jHNo19JR5asAmcVeXHa0gItLRlYL64UPNeO66GktTfApSUCInslllU7WmGuoTx42y19fWDsfmlbmjSnRFCDQCyuW1OXA8R0C5AJ6ywxkHG9ChKN581zZ39Reu9KHOuvoe2hvnrpvSrnu76BVX+/c4vuJ4jvLvPvObAiGEEAOLAiGEEAOLAiGEEAOLAiGEEAOLAiGEEMOA3Ufa5jd2oLg6at7Jiv58CjyJZu7xHBxCRce5nVCXUR63AZxFPabWTMitAUkARG5UVyXh2LTSfGbH9h1Qr2m33UfhEI55SFTgBjHNLdg5pD0SqR67mVAv0EREEnHcfMcr2vEc//sXlqRFYqT6cGxHGDiYRERCiuMpFrevSzCCIzEKjnEW6D3UXGrOsRXqh1AJCysz6JzKt4zBnPtP8JsCIYQQA4sCIYQQA4sCIYQQA4sCIYQQA4sCIYQQw6BlH6Fd+KKa04F1v+ZOAM6Hoh8HjLjmE6HmMyIifmRBUWwpai6MshTYPMXZVuDaaMTBDaI6zLBeVK4hch9FItgJo13bCsXFs3PHbkvL5rJwbDyKs4IahlZDPZ3G86AlZpSMo0wO614BXyvPs8drDZO0G4Gut4jeTCkL1oL9W/ox9VfcwY3o2nzGQXdzS+q6fqID75jltJZBsB/xmwIhhBADiwIhhBADiwIhhBADiwIhhBADiwIhhBBDGbKPSt8p1zo+eYpzqFgsvT2aTxmrdTtz1YuoU5lLJzURPeIJhCXpMUSK40kPhlHGl35/NNeYp7SUUl0iYHxzaxccW5WshPrIxhFQP3DosKVt3oBzkjSHUG1VBdR9il8n1W13h+vLKt4exQmUzeHsI+SC8ylOJY2i4PwoT8lEqgrYTjAtb8nZqVaidiS0Y+rPJ3LrOLqJ1HwmDRdXn6srCR2NndcIIYQMIiwKhBBCDCwKhBBCDCwKhBBCDCwKhBBCDIPmPkKuBS0Tx1P9KqW7e3x+rTuY5mAauCtJNR+5djBDbirHzCbXYBjcCQuPLRQKUA8E8EE7O3ugvnvPfkurHdIAx27bsRfqE8ePhjq6huk07kjW1Y3X19LWBvVgQMkQAs+4lk/kU3S/8tx6Pjt1KKZkNlVXV0EddVITEYlGcX4UWonqPoKq/jfQ7ebYMU1365TuHHKcQdfL4Chydx8x+4gQQsi7DIsCIYQQA4sCIYQQA4sCIYQQw+BtNHv25qS2aeVT5tA3W0EshOe2caxu+jpsWKPeONrYIxwS/oXjNrPzP3DZ5NJ6u7S2dkK9rR1v5GYyduxC0749cGw8noT6o088A/UwiEopKI1tgso99gdxSxnlscXXRYn+0CYJKJvYQbCW2soEHJusxNcqrGwo55RoDRwX4dp4aRA3mh02sbVpXDeIy7Oh7BZPcrThNwVCCCEGFgVCCCEGFgVCCCEGFgVCCCEGFgVCCCGGgbuPFB1FWhSLOC7B1TlT9Oxa5tdcRmpshTLcwcWkjdVwGl0m+1FAc1MBPZ/HrpTWVruZjIhIc0uHshb8VMRiduxCS0szHNvdg48ZCWNHTTabtbRiAbuP/KCpkYhIWHECRbQoCqDlHRvhaDaeRCxiaZpravvON6A+evRIqEej9twiIgXXtQOOjvuo9LU4u4wccyTwMUsfKyJ6Iy0UTcMmO4QQQgYTFgVCCCEGFgVCCCEGFgVCCCEGFgVCCCGGQcs+KhRsvaA02dHnxrofZIkU9SAiLGuuJGUtuMmOayMct2MitKYs2lp6+7CjqLm5FYy1HTwiIn1pO7NIRCSvZAu5EAyGoN7bi/OTcrkuqAf89qOsPZt55TnMK/lEIaWZUBTkE0VCOD9JW4tPe27BM364tR0O7VHuW0cHvlZ1ddVQDwTstauNl7SGWbrVpuSxro1ttEXCLCfVrFOehj+4eZXbeWpZcDiaiu4jQgghgwiLAiGEEAOLAiGEEAOLAiGEEAOLAiGEEMPgdV4DOUd6topjHkkRuEFA5y2Rd9B5TW2aVnrnNd1PhM8H5Tb5/NjF0tfr5jRp1RwrPba7x6+0WNMcT1oHL20e5MxAGVkiekeyQgEfs4ByjhzupYhIUemQlcnh8dm8fT6aUymgPoc4D6y7z3Z8ZZT3JxTCDq7DzS14bnDvRUQSCTubKlFRAceGw2Goa2eJnEC405scyX7kNBw7nrTB2hSO2UfAwaZmNilut6L2/oDns/zeI35TIIQQ8jZYFAghhBhYFAghhBhYFAghhBhYFAghhBgG7j7SdtCBq6SgdV5z7IZURG4d5EgS3U2k5xCplhVwTG1qzcWD9XTWdtR0dHbAsZ0dnVDv6+uDei6Hc4uQ8yMP3DQiR3BwKXpBcSWha6g9P65dqVx8GPrciqz+6GTPkwWZX29O7eZ4QuODissoEMCvcTaLn4me3l6o5/L2+9nRiV1tsRjugJdMYLdSNGJ3e9OeK82to7qVHNyLztFHZejI5vyMu7iyBsF+xG8KhBBCDCwKhBBCDCwKhBBCDCwKhBBCDAPfaFZ2OlATjkLBbaNZ3YQDO38oKuKIOEYg+EHsgrZxnAUbxyIiqRSOF0h1d1taOp2GY/N53Ngmn8fH1GIk4CaXsmnlshn65jTqRKUe0hm0Eve5lYeiDIvU7oO6SQqWUlDucVDZaA5HcBRFRnm2wiE8HpFKpaDe04M3saNRe6M5HovCsdomdhA0ARIRKaobuVB1GPsONprha+W20aw12Xm3dpr5TYEQQoiBRYEQQoiBRYEQQoiBRYEQQoiBRYEQQojhXY25UJ0wyhw+ZMEQEZ/PHq/4mlRXUkBxMojS3CWdsZ0fqS7sJurusd1EIiLZjBY5gZxa+Fqh5kUiIp52baGq4TZacyWp0zgaxPDcZXBbqOtwa+ICHU8O78ORFoOecZ/ybGZzuPFSKIhjMbQYlmzWfj4jUewQ8vvw+4MawYhgN10mg9fd04vjOaoqk1CPKA1/nJrSlMl9BKM1NHeU21JgzAeb7BBCCBlUWBQIIYQYWBQIIYQYWBQIIYQYWBQIIYQYBi37CDbZURw16g6/Mh415whpuS2KS6KnV3M+YEdRH3BEaK4PLeNJPU/gTtCcPWpjDmcG7mTQmqSoWUnITebaM0fLuALjfa7eK4feJiIiPj9o9gQ0EZGA4vjRGk+h7DBtfUr0kZqTpTnvUH5WSHmWNQeTZrLyw+uCTyiXw+vWGv7UVFdCHTUfUt9BR12PPnLIJ1LtRw65SmX7PPgT/KZACCHEwKJACCHEwKJACCHEwKJACCHEwKJACCHEMHD3kdY1DXXZUsZqboNkErsK4hUVltbR0QnHNrc0Q72vD+eraB3MkCNAdQhp+TeqwwGqeB3OuHWaKgeqKwlYU/zazyWuOUkgK8jV9OHajQ/ryuzKaWrnj7Ks1G5fCtrzpnUMRKeTy+H3IRKxO6m9OYXSjQ+sRVuHlhOVz2MnlJaVlASfE85uHSeXER6vZxw5Op4GJenIht8UCCGEGFgUCCGEGFgUCCGEGFgUCCGEGEreaNY2YItapAPYLMpl8YYy2jgWEWkcNQrqfaBhR09vLxyrpSJkMvYcRwJtHjtv+5Rld9f11+4HE6U5kjIabUBrMQ8BdTO09JiLcuGUxKFukGub1aW38NFOXUNrMKVt5KKNX+29D4WUBj5KzAdsAuV33DhXnpVsBn+u5GP2eL+2Ea4d1DUWo/Qp1KOq0UHI7KJuyuP7Fgz+5Y98flMghBBiYFEghBBiYFEghBBiYFEghBBiYFEghBBiKNl9pO1ax+JxqGtRB4ix48ZCPRKLQr0rZTfbSCYScKwWZ5FKdUNdi9woC8o1cU10QJTuYXGfRXdPqLkQEOSG0Z4T6FYRrVmLOFlzUCKGyJFiJBxcVu4WISwj3fHUlT444kfNjkTEA7rmbil62AkUCuJmVwUHe1gwiJsAocZDIiKe1tQJacr1Vp8J7Z11ch+5vZ1a/Ad6V7S4kVJcRhr8pkAIIcTAokAIIcTAokAIIcTAokAIIcTAokAIIcTg80rsOnH1VVdB/ZVX/gD1zZs3WVpY2SmvrauFurY05CjSXCzpdKbkOUREClqTnWOE8kX8OMz07vT26H9IRzvVMePgUtfn2EyoDDlZLvk8IthppGWbae9bUMlEQo4aLZtJz09yyyEKh20nlIsr8n9ndxwPZnCcQltjNpu1tFFKPtzcufOgvnTp0r94fH5TIIQQYmBRIIQQYmBRIIQQYmBRIIQQYmBRIIQQYijZfeS6a+8DwStaRsnRQXE+lMPGQsrAu+8SKcczoWUFHUsE/DhbCHVTCwEHj4h+d9IZ7PbLZrFeHkrPFNPzrd4DoAfR0dpUysc9vykQQggxsCgQQggxsCgQQggxsCgQQggxsCgQQggxlNyeR+vwUywonZmKIDNFcT0cDUo0XZH3DA6d17Rub8oz4eIoioTxe1JXUwP1EQ3DoT58WIM9dvgIPMfwkVCvr6+HeiJZCfVqsMaaWrzuSDQG9b7eXqjv3LXT0jZv2gjHrl+/FurrNm2A+oFDh6BeKNg5Zi5dzd7k2PmcQI+nTzmfQOCdf9bymwIhhBADiwIhhBADiwIhhBADiwIhhBBDyTEXwQDek35P/9o4+ZtE2zj2K5tzdckE1BuHVFvayFpbExEZ1zga6g3KJrE/aL9v0Vgcjg1FolD3tIY/IIJGRCSfs5u45LJpOLYINnFFRIIBPDf6nMgqDbBySqOrQ4cPQ33rrt1Q37J3v6UdbOuEYwvIGCMiAa3hz3v0Y6+gNE16O/ymQAghxMCiQAghxMCiQAghxMCiQAghxMCiQAghxFCy+2ggvzZNSLnQwgiK8DHGo+ursZto3BAc6VBfiSMdgmI7ObwcdtQEBDueCooTKCf2++b34XdQMchIQXFZxcLYSVhEl9BT3CqarrgRkepXYm+KSjOuvGKnyispJLmiPb6l23ZYiYhsbWqFek+6D+oBJV7iWDcl0X1ECCHECRYFQgghBhYFQgghBhYFQgghBhYFQgghBofsI+wUONZ328l7E9VlBC0yIsGg/XxOGIqbyTRU4qygWAAfNeTHxwz4bD2oLFxr7pLzYSdQzrPPJwTOUUTPG9JcSdpaQuAdD4ZCeA6QzXTE8aCJTS6PnTDZLHYI5ZW8pXQGO75SvbZzKJvH97Inh/WtBzug3pHqhjpyJR1Ln5F0HxFCCHGCRYEQQoiBRYEQQoiBRYEQQoiBRYEQQogBWwgAx9IOOvnrwS3LSCQSwe6WyUOTllYbxW6dsGAXS1TJIQoB54yISAgM1zp1dSuul7zqeLJ1pImIhIN43WHFCRQIYr2iws6Eqqypg2P9wTDWQ1gvAOdQpq8Xjm1pa4N6pqsd6nnFURMCDikP5FWJiFR4+JmYOqIW6puboCxtwJX0XstJ4jcFQgghBhYFQgghBhYFQgghBhYFQgghhpI3mgkZDLTNtoAS3XBcXRzqQ8H+ZiyAZ68IK81qlNWgiAYRkRDYQOwraA1ilM1gJT6mKmlv+saiuNlPLKrEdiSroB5J4PiPRLLa0qIxfL19yjXJ5nJQb2s+YGk5ZWxU2SDPKdEaWWUDPpNVuu8A/MrzFlQa/syYMAbqr2zbY2mp3h58TGXdpQUPDR78pkAIIcTAokAIIcTAokAIIcTAokAIIcTAokAIIcRQsvvIr0QAeJp/BMjqWPI3S7GI3R3vH4bjBUZVYzdMsGg3Wokp8Q/aT0JaHIFPefZ78/batRYmSSWeI1GFHUJDGxotrba+AY71a7EVyRqoR+L4GhZRExvFCtPdhaMoelJdUM/02Lq/iJvp+IrYleRToijCyg3NAHeP1mPG58MuMFEaLFVVYgfX+8ePtbSX12/Ac6tP4tH9nOQ3BUIIIQYWBUIIIQYWBUIIIQYWBUIIIQYWBUIIIYbSs4+Ubig+tU1K6WNdXUnYEEFn07GClotTANaPscPr4djzF8yH+hvbN0O9o3m/peU8ZR1QFQkr4/NF/GwVgBwPYydQjeIyqho2HOrRCrtpkPaIa+6oTF8K6rk01vN5+8qEwkrTnEwfPmYvntvn2XNnurFTKZ3FriT0/IiIFJT7FgJ5Rj4fdrtlsLFJzSfS1lhfa7vmKpT8qN40bjKk3c93C35TIIQQYmBRIIQQYmBRIIQQYmBRIIQQYmBRIIQQYihD5zXVljTQGfTxwN2iOZh8SnaLpx7VwcWkxj79bTuhNPcR4ow5c6A++fjpUN+8bjXUC37g+lHuvU9xE+WV8fEgPp8EcBqFIthpElEcKF42DfVcd7u9vt5OPIcf5/YEQ9g5lKjETih09pkefEzt9VHzo0o8nohIPo2dTTmQNfXmPHgxKK8tp3TG8yvrDgLXlIiIT1l9Imm7xrScpJ4+7D7SrqHL54qLK/TP4TcFQgghBhYFQgghBhYFQgghBhYFQgghBhYFQgghhjK4jzTK4MDRpvDZf6HutStOGH1vXnNP2Mf01LkH0X1UeqO7v/g3g4XWTS0UsF0yjcOGwrHbNq6Dem9PN9SDQftRLhRxoE1QuSYBxX0UCWAXTzwSsbRQBI/1FbGLJZ/pgXoWOHA8JYdHyyfyIjGodyudzYLAOaU5mDSDmQ+8myIiqQ67U1tOyf4pKNeqCLKZRESi4D6IiOTBInN5/ExkFFdSQXGqhcDzJiJSXW13u4tFonCslnEUCGI3mac8n+WG3xQIIYQYWBQIIYQYWBQIIYQYWBQIIYQYyrDRrO4GO4x1mKI8g9/BLC7zu25uD3jq8qzbcYFanEVWaUBy3PvGW9qY4bjJzPbWA1BvHInH93S02GIRb9jFArgRTlUF3pgNBPBrEgEbgpVgo1FEJBKrgHo0icfnwM9r6YzSfEbZUO9N4YiKLqW5TRBsiFZU1cGx2RxeS9OeXVBvaT5saXEl+iMRxdcqHscbzSklKiSbtz9vMkpURtGH77E/jJ+JiiSOCgkE7Y35nNIcSGvgc7ThNwVCCCEGFgVCCCEGFgVCCCEGFgVCCCEGFgVCCCGGYzvmYhCPVw63jkMvmaPHIN4Gv+MFGD9mlKWNmTARjn296RDUDze1Qr0zaztqwj7syqmP4ViE+mENUK+M45iCfN524EQqsCslGMRzVNbUQt0Xtp05PYqrK6PERQSUKIY+4AQSEWlvbba0VBse29WJHUwC3DciIiNrE5ZWG8X3x5fA17C7E7uM0thQJIe67EZFfYojrejDDqFkGI+vSODGOahRU0cXdoFpjX3epTQLFX5TIIQQYmBRIIQQYmBRIIQQYmBRIIQQYmBRIIQQYnBwH2lOE+euL6VP7XpMB1wSm97TOF1Ct+tdVGwSWibS6zt3W9pjK5+EY+979OdQbxyKs4JQk52OPiUTJ4edJpnMG1AfBZwzIiJDEraLKV/AjppEEmcIFfO44U2swj4fXxTn8ETiOCuoohofs3rIMKiH0rZLJpTFTYB2KRlHTV14fAw4uHp7sJPsjNOOg/rvXtwI9WQAX5dEOGVpfsV95CkNbyoqcD5ThXLN23ptJ1hfGj+Huvvo6NqP+E2BEEKIgUWBEEKIgUWBEEKIgUWBEEKIgUWBEEKIwcF9VA7Hj+JW8RxdRseKRcj1khyNdTut0e2ENJdEOIQ7m72+e4+l7dy9G449YdRQqG/esw/qYye+39ZG4C5t/k6cqxSL4Nchk8MOoSwwGgX6cBBPAWQZiYgEgvhahYAer8B5Oz7QMU1ExKd0jAsKdl/50rZbp9iNHUI50HVORGTr7/4A9YmNjZa2vgtf1xdefBnqiQjOROrNKLlFUdAFLa2cewjnYWn5XgGla1oBdFkrFvEz4fdrH790HxFCCDlGYFEghBBiYFEghBBiYFEghBBiKH2juQy5ED7HnVZ1uwX8Rbka3jilcxwrG97lwvEea5twObDZJiJSW21vFI6XNnzIajx3OI+jG2afdoqljavHDWwObMabob5cH9SLmQzUA2CzNVE1BI6tHDISzxHAG8093XYTm6hyH5IxHPMQUmIx/FpsSd4+z9ZDOPpj77YtUD/n//wd1H0gLiNXjzd3Y2EcK5LK4M3tQBBvWMej9vwp5R4XlM33eBwbBKIxrBfa7M16PbbiKHfTUeA3BUIIIQYWBUIIIQYWBUIIIQYWBUIIIQYWBUIIIQaHmAuFcnSrKUeaxaBHTtgH8JR4DueeQcc42rLzistI+xfnHWdHVwyP4bH7erCj5O9nzYL6lGknWlohYzc8ERHxlJ+Ferq6oZ7L4YerIma7W+IedsgUlWcl1dUB9b607ZLxWpR4juYDUI/Gk1iPKE1pgnYcQ6GI111XhSMnDu/ZCvXREydZ2vCG0XDsqxt3Qr2zgO/DqKG44U0gYevdGfxc9Qm+bxHlGqZStstIRKSQy1qa1kznGDUf8ZsCIYSQP8GiQAghxMCiQAghxMCiQAghxMCiQAghxFCy+8jVZITiPhxb6ajAyJ2y7eSXo5kQpizmo0GdXDlkER80FMbZNeefMBbqk2vsn0FyfpwhU1WJH82D7dj1MRWspUdx6zQdxnlLxTTOOCoq519EN6MdN6XJZNJQzys/lwWitnOmUARdfUSks+0w1H3K+JDSIGdYne0o8uH+MNLcg+dO2+YbERHZ/LvXLG1fO3aHVdXgzKoZ4xvw5HmcZ9TdZy8mqOR1hYL4WS5klRMK42clEbedXX4/vt6eKBfXhUFwMPGbAiGEEAOLAiGEEAOLAiGEEAOLAiGEEAOLAiGEEMPAs48UBtMgpDYyKnEdb07i+g8GjrbusnRwc7aHgaFKRks2i50WU8dPhPoHpkyG+us7Xre0ehwtI9OmzYD6r/+4Huqv/v4FS0soT3eqFzuBMmmci6O9JD54EbE7Kg2yjEREsoqzKRy1XVmRCHbIFAt43XmQwyMiklEeuLDPXkssjDvDwXMXkd0tOD9qb6t9XaaMxC6jk6aMgXo+j906Xcq17QHuo0IRz5HpVXKvlK57VRV2lpOISF1tvaX5/fh6F5QsJ5cPocH4uOI3BUIIIQYWBUIIIQYWBUIIIQYWBUIIIQYWBUIIIQYH9xHeKffKlmiEGHj7Nn19yhGdDAHlafc2qDlRDv+gqDgzgkHsQNmyYxfU72jBWTzIDTK0CnfN2rQPzzGqvg7qDQ12Ls729a/CsZkcdutolyqtOITyffY8vTncjS4cwq9aRMkhyoNObekcvj8+xd0S9OG5RemY1wU6z6WVdVfF8NyNNfh+Vkfs8fVx/DPpG3v3Qj0QxjlZmoOrrdt2JRUK+BrGlGe8L43zmXo6cX7W1El2B8BhQ4bAsXub9kM9pKzF8+y1D8bnL78pEEIIMbAoEEIIMbAoEEIIMbAoEEIIMfg8r7TQCG2zUWcQuj8YBjNEA2/cuKhOu7vOOG6cK7rLCl3nyOfxRu7fzZhuaWMb8CZcd3sz1OOCoxsqKkBehrKhnO7ugLrqMVA2cmHzHWWzPqA8E8kofq8SyWpL84fxJm5OaQQTUJq4eEosRlDsxjnhAD73jLJhe7Abzx0G3XoCHt7wDoGIDxERfwjr2loK4KMtEg7DsV5BaWDU1QH1vB/ftzP+4ZOWtmbbDjj2jhV3QT2srdEl30chqzUNehv8pkAIIcTAokAIIcTAokAIIcTAokAIIcTAokAIIcQwaE12Bpd3O0KjXMccPNRGPYO4bO2QWjOYhtoaSytmseujpRPHC4jiBKrN2U1cKoq4mU5YmSOvuDvU5kjg4mI/jUhPFjtkerK4QUwtGF4Rw86RvNKspbcPz63FfATBdYmFcJxFN75tklbWglIxAspDm+vGjW1CMcWplaiEek213cQnqDy0na2HoB7w44/I7h7cTGn75nWWdsrMv4Njn3nfBKhv3YndSsiVpEXTDAR+UyCEEGJgUSCEEGJgUSCEEGJgUSCEEGJgUSCEEGJwyD56bxqVtHWrp63Ifr9dP/N5bMEIKI1T9HAdRQcUlAYpMIdHRPyK08ZtIW7XqgiagYiIVFYkLO0f58+HY3fu2gb1XBD/HNM4eqylZZrfgGPzvV1QDwSUn5F8WPfythtIyyHqTOP7lgXNdERE/MCZE1FyiLSMo6LyjBeV84mChjp9SmOfovKsDIljhxBqHONFsWtItdIpz1tFBc6EGlE/3NKKWexI61SytrQmO5r7yA9ym+ae8zE4dtu+A1D/9x/+EOqxWNTSNPeRpjP7iBBCiBMsCoQQQgwsCoQQQgwsCoQQQgwsCoQQQgzvTUsRcD54iuMlk8E5KuXA78cuo/wgHjMQwMfU8oZySs4Nul5qfpJCWDlmb28P1Me/b7ylHVSyf9a+gZ1DoxsaoL53335LSysOkYLSeS0Zxq9DVnGgRIGbKlI9FI4N46Zh0nUQO1DaOzrtdeSxgykcwZ26wpEY1POKM6Wvu9vShiTxHEk/dt6lpQrqiUb73muxPVmlc184jNcyesxEqAdAN758Fj+b6UP28yMi0tfZCvV8Dp9/b5ftbNu1bRMce+rfn4X16dOh/uKa16COiEZsp1Kp8JsCIYQQA4sCIYQQA4sCIYQQA4sCIYQQA4sCIYQQwzGdfeRT7DAo/ycaxbvtX//616G+edNmqGtOjnHjxlnaTTfdBMdedNFFUB8zZgzUUa7SunV2BycRkY0bsZPhqaf+H9SfffZZqF999dWWpjm1broRn+eSS5ZA/WMfw1kv11xzjaUtOPscOPYr110L9fMWLoT6D//r+5ZWXY2dMHOVvKXOtjao11baLiMRkaX/93ZL++zXvgHHalk0d9+5FOqXXnGFpR06dBiO/f1LL0H9+eeeg/qwIXYHPBGRxZdeZmlartLQeuwCW/fbX0O9FzibFnwcPz979uyF+vvG2w4mEZHH7/kJ1M9efLmlLVz0CTj2E7OOh/rpC86Geqi6DuroXe5swQ6mQ4dboH7eoouh/psXXrC03676LRz72+exXsrHPb8pEEIIMbAoEEIIMbAoEEIIMbAoEEIIMbwnYy7QZkkwgE/luuuug/qDDz4I9e3bt0P9y1/+sqXdd999cOw999wD9dtuuw3qyaT96/jaBvmECROgPl7ZhHv66aehjjaVtY19n9KoB22+i4i8oURUoCgOv9I55cABHP9wwYUXQv0XT/zC0i65zN44FRGZMfMDUP/GLTdD/aKPfBzqyx98xNLmnHYaHFtQNvgee/RRqF/x6c9Y2v3K83bv/2A9HsT3bcaM6VD/2jdutbTPXnkpHJvq7MC6H0efnDBvjqVddIm9ESwicv6Zp0P9upvwO7F2/RqoZ3rtze1EGDcBysXsd1BE5PO32gYGEZHvfAM/KxMnHWdpl3wOmyYuUM7zPz/0IahXVtsGgZFVtXDsyZOmQL0U+E2BEEKIgUWBEEKIgUWBEEKIgUWBEEKIgUWBEEKI4dh2H5UUwPEmRaXJTlNTE9Q1d4um796929L27sUum9WrV0M9HFaaoQD917/GcQFa1MH+/bhJSDSKG5OgX8fXohj27sWxA9oxK4GbSkSkvb29JE1EpLkFRwAcPozPvxVEVPz6V7+CY+tqcURBRxuOI9izcwfU28Ax9yvPmxYh0taOozXagb78Lhzn0LT9dai/rwHHWTTt2gn1jevWWtqosdjVNmrMWKj7V+Fr3vy6HdvS2oqv9/EzT4L6wSb8vDXv2gb1xsZGe2wrvt59nVjfvG4N1OuVZk/RuN1N6Q+/xXEjXjYN9bb2Dqg//cunLG2E0kjp3Hk4yqUU+E2BEEKIgUWBEEKIgUWBEEKIgUWBEEKIgUWBEEKIofQmO0q2kIYHrENato4raMl+H65vQ4cOgXpvXx/UA4EA1JcssRuC7NmzB459+eWXof7EE09A/fHHHrO0n9x1Fxzb09MDddR4SERk8uTJUE+lUpbWobgeDjc3Q/388/8B6scdZ+e/iIg8/PDDlqa5j7LZnDL3RKg3A1dSJpOFY6urq6E+afIkqG/buhXqGzfZDY+mTMGZM1WVuOFPayt2WaVAU5oTpk2FY0+fPRvqv3rqSagPbxgK9SnT7EYzB7euh2MDfZ1Q9xfzUPfA85nO4Wd2SMNwqHen8f1s34/dcb54pS0GsQMwn8FOoKqqaqhXVuH7mU51WNreXbvg2Jzy0RtNgHWLSDJmO5vep7jD6upt55WIyJW3/jvU3w6/KRBCCDGwKBBCCDGwKBBCCDGwKBBCCDGwKBBCCDGU7j4KKu4j5V8j99ERlqHoLnNgtDwfjWg0CvUdO+z8G80JNH8+zh3RMoRuvdXueDVz5kw4VstPuvxy3MXq9ttvhzrKZ/rc5z4Hxy5evBjqZ555JtSvueYaqM+cMcPSXluzBo496SScf/MrJc/oqquusrRbbrkFjl25ciXUtXyi888/H+roPn/ve9+DYzdu3Aj1K6+8Eurf+Y7tEslmsfvmzjuXQf3j/7AQ64svgfr5H/2Ypc15/1g49l+/g7sIBpM4b6m3t9fSIgXs+Fn2H9/G+qN29o+IyK4duFvi7f9uv1f//Fn8jHem8Lt8UMlCe+1p7CRsXf+KpUWr8DXxisrnWx7f52TU7hqnuaASVTjf66sPYEfa2+E3BUIIIQYWBUIIIQYWBUIIIQYWBUIIIYaSsytK245+pwze5Go8h7K3nU7jzS+0UdaiNIJBzVeOBIrLmDQJRy4cf8IJUK+pwZtZo0aNgvpTT9mbdrW1tXDshAkToK412dE4BKIotOiTUMjeVBPR14ia70QiETh22LBhUF+jbHprsR2VlXYcwZgxY+DYV16xNyBFRKqV+/b3p55iaQ8/8AAcq5FvOwj1bApHVCB8WRwHM/fs86D+8qrfQP2V55+xtFPnLYBjw8pm9dAhePP0vh9+H+qta16wtJ3bz4Fji8rPx9OOnwb13ha8Af3rV1+yNGxdEYkrppZ4OAH1oNixIEgTEcl34/iYUuA3BUIIIQYWBUIIIQYWBUIIIQYWBUIIIQYWBUIIIQYH95FbXMSxQsHDu/OuDX+WLbOjBKZOxU1PRo8eDfVHHnkE6sh99MILtnNCRI/KQO4oEZHW1laoI+fQgw8+CMe+/vrrUNdcVqiZjojIxIl2g5ympiY4VnN2/fznP4d6M2gEpI3dsmUL1LW13P/A/VBHjYq0a6Ldh+XLl0N9x1Z7jRs2b4ZjH1BcSYF6/Bze+/DPoO5P2K6fdBVuePPPSjzHSTPtKBMRkap6e54nVuKoiDVb8POm3c9frrIdPyIirzTZLqupW/HcsTB2u4Wi2MG2Zgd+D1ftsZ/byjbsaPQrn0FBP/5Z3Q90bQ5RPq9vxKP7z1nCGEIIIX8jsCgQQggxsCgQQggxsCgQQggxsCgQQggxlNxkhxBCyF8//KZACCHEwKJACCHEwKJACCHEwKJACCHEwKJACCHEwKJACCHEwKJACCHEwKJACCHEwKJACCHE8P8BlcEk20oc8UkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터화된 이미지 텐서:\n",
      "tensor([[[-1.0048, -1.0048, -1.1589,  ..., -1.1075, -1.0048, -1.0048],\n",
      "         [-1.0048, -1.0048, -1.1589,  ..., -1.1075, -1.0048, -1.0048],\n",
      "         [-0.4397, -0.4397, -0.6452,  ..., -0.6109, -0.4397, -0.4397],\n",
      "         ...,\n",
      "         [-1.3473, -1.3473, -1.3473,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-1.6213, -1.6213, -1.6213,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-1.6213, -1.6213, -1.6213,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "        [[-0.8978, -0.8978, -1.0553,  ..., -1.0028, -0.8978, -0.8978],\n",
      "         [-0.8978, -0.8978, -1.0553,  ..., -1.0028, -0.8978, -0.8978],\n",
      "         [-0.3200, -0.3200, -0.5301,  ..., -0.4951, -0.3200, -0.3200],\n",
      "         ...,\n",
      "         [-1.4580, -1.4580, -1.4580,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-1.6681, -1.6681, -1.6681,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-1.6681, -1.6681, -1.6681,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-0.6715, -0.6715, -0.8284,  ..., -0.8110, -0.6715, -0.6715],\n",
      "         [-0.6715, -0.6715, -0.8284,  ..., -0.8110, -0.6715, -0.6715],\n",
      "         [-0.0964, -0.0964, -0.3230,  ..., -0.2881, -0.0964, -0.0964],\n",
      "         ...,\n",
      "         [-1.5081, -1.5081, -1.5256,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.6476, -1.6476, -1.6476,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.6476, -1.6476, -1.6476,  ..., -1.8044, -1.8044, -1.8044]]])\n",
      "텐서 크기: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "# 이미지 경로 및 로드\n",
    "img_path = os.path.join(\"osai-project\", \"train/42953.png\")  # 테스트용 이미지\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "# 이미지 시각화\n",
    "plt.imshow(image)\n",
    "plt.title(\"Loaded Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 이미지 텐서 변환\n",
    "image_transforms = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "image_tensor = image_transforms(image)  # 이미지 변환\n",
    "print(\"벡터화된 이미지 텐서:\")\n",
    "print(image_tensor)\n",
    "print(f\"텐서 크기: {image_tensor.shape}\")  # (채널, 높이, 너비)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/envs/env1/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/anaconda3/envs/env1/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/anaconda3/envs/env1/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1586072/2049076197.py:178: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # Mixed precision\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1586072/2049076197.py:197: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12]\n",
      " Train Loss: 0.6435 | Train Acc (0.5 thr): 63.59%\n",
      " Val   Loss: 0.6723\n",
      "   Thr=0.30 | Val Acc=60.25%\n",
      "   Thr=0.35 | Val Acc=60.61%\n",
      "   Thr=0.40 | Val Acc=61.60%\n",
      "   Thr=0.45 | Val Acc=62.82%\n",
      "   Thr=0.50 | Val Acc=61.84%\n",
      "   Thr=0.55 | Val Acc=60.74%\n",
      "   Thr=0.60 | Val Acc=53.37%\n",
      "   Thr=0.65 | Val Acc=51.78%\n",
      "   Thr=0.70 | Val Acc=51.78%\n",
      " => Best Thr=0.45, Best Thr Acc=62.82%\n",
      "*** Best Model Saved! val_acc=62.82%, thr=0.45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/12]\n",
      " Train Loss: 0.5536 | Train Acc (0.5 thr): 74.49%\n",
      " Val   Loss: 0.6392\n",
      "   Thr=0.30 | Val Acc=70.43%\n",
      "   Thr=0.35 | Val Acc=70.31%\n",
      "   Thr=0.40 | Val Acc=68.34%\n",
      "   Thr=0.45 | Val Acc=66.26%\n",
      "   Thr=0.50 | Val Acc=63.93%\n",
      "   Thr=0.55 | Val Acc=62.70%\n",
      "   Thr=0.60 | Val Acc=60.37%\n",
      "   Thr=0.65 | Val Acc=58.53%\n",
      "   Thr=0.70 | Val Acc=57.55%\n",
      " => Best Thr=0.30, Best Thr Acc=70.43%\n",
      "*** Best Model Saved! val_acc=70.43%, thr=0.30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/12]\n",
      " Train Loss: 0.4958 | Train Acc (0.5 thr): 78.21%\n",
      " Val   Loss: 0.5690\n",
      "   Thr=0.30 | Val Acc=72.64%\n",
      "   Thr=0.35 | Val Acc=72.76%\n",
      "   Thr=0.40 | Val Acc=74.11%\n",
      "   Thr=0.45 | Val Acc=73.62%\n",
      "   Thr=0.50 | Val Acc=71.66%\n",
      "   Thr=0.55 | Val Acc=69.69%\n",
      "   Thr=0.60 | Val Acc=67.73%\n",
      "   Thr=0.65 | Val Acc=65.40%\n",
      "   Thr=0.70 | Val Acc=63.80%\n",
      " => Best Thr=0.40, Best Thr Acc=74.11%\n",
      "*** Best Model Saved! val_acc=74.11%, thr=0.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/12]\n",
      " Train Loss: 0.4429 | Train Acc (0.5 thr): 80.74%\n",
      " Val   Loss: 0.5452\n",
      "   Thr=0.30 | Val Acc=76.32%\n",
      "   Thr=0.35 | Val Acc=77.30%\n",
      "   Thr=0.40 | Val Acc=76.44%\n",
      "   Thr=0.45 | Val Acc=75.09%\n",
      "   Thr=0.50 | Val Acc=73.50%\n",
      "   Thr=0.55 | Val Acc=70.55%\n",
      "   Thr=0.60 | Val Acc=68.10%\n",
      "   Thr=0.65 | Val Acc=66.63%\n",
      "   Thr=0.70 | Val Acc=64.79%\n",
      " => Best Thr=0.35, Best Thr Acc=77.30%\n",
      "*** Best Model Saved! val_acc=77.30%, thr=0.35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/12]\n",
      " Train Loss: 0.3949 | Train Acc (0.5 thr): 83.23%\n",
      " Val   Loss: 0.4779\n",
      "   Thr=0.30 | Val Acc=77.30%\n",
      "   Thr=0.35 | Val Acc=78.65%\n",
      "   Thr=0.40 | Val Acc=79.39%\n",
      "   Thr=0.45 | Val Acc=79.88%\n",
      "   Thr=0.50 | Val Acc=79.26%\n",
      "   Thr=0.55 | Val Acc=77.55%\n",
      "   Thr=0.60 | Val Acc=73.99%\n",
      "   Thr=0.65 | Val Acc=71.66%\n",
      "   Thr=0.70 | Val Acc=69.45%\n",
      " => Best Thr=0.45, Best Thr Acc=79.88%\n",
      "*** Best Model Saved! val_acc=79.88%, thr=0.45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/12]\n",
      " Train Loss: 0.3503 | Train Acc (0.5 thr): 85.10%\n",
      " Val   Loss: 0.4508\n",
      "   Thr=0.30 | Val Acc=80.74%\n",
      "   Thr=0.35 | Val Acc=81.84%\n",
      "   Thr=0.40 | Val Acc=83.19%\n",
      "   Thr=0.45 | Val Acc=83.44%\n",
      "   Thr=0.50 | Val Acc=81.23%\n",
      "   Thr=0.55 | Val Acc=76.93%\n",
      "   Thr=0.60 | Val Acc=74.11%\n",
      "   Thr=0.65 | Val Acc=69.57%\n",
      "   Thr=0.70 | Val Acc=67.12%\n",
      " => Best Thr=0.45, Best Thr Acc=83.44%\n",
      "*** Best Model Saved! val_acc=83.44%, thr=0.45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/12]\n",
      " Train Loss: 0.3150 | Train Acc (0.5 thr): 86.80%\n",
      " Val   Loss: 0.3996\n",
      "   Thr=0.30 | Val Acc=81.60%\n",
      "   Thr=0.35 | Val Acc=83.19%\n",
      "   Thr=0.40 | Val Acc=84.05%\n",
      "   Thr=0.45 | Val Acc=85.03%\n",
      "   Thr=0.50 | Val Acc=85.52%\n",
      "   Thr=0.55 | Val Acc=83.44%\n",
      "   Thr=0.60 | Val Acc=80.49%\n",
      "   Thr=0.65 | Val Acc=75.09%\n",
      "   Thr=0.70 | Val Acc=70.31%\n",
      " => Best Thr=0.50, Best Thr Acc=85.52%\n",
      "*** Best Model Saved! val_acc=85.52%, thr=0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/12]\n",
      " Train Loss: 0.2796 | Train Acc (0.5 thr): 88.78%\n",
      " Val   Loss: 0.3501\n",
      "   Thr=0.30 | Val Acc=83.56%\n",
      "   Thr=0.35 | Val Acc=84.54%\n",
      "   Thr=0.40 | Val Acc=86.38%\n",
      "   Thr=0.45 | Val Acc=86.99%\n",
      "   Thr=0.50 | Val Acc=87.61%\n",
      "   Thr=0.55 | Val Acc=87.73%\n",
      "   Thr=0.60 | Val Acc=87.61%\n",
      "   Thr=0.65 | Val Acc=80.74%\n",
      "   Thr=0.70 | Val Acc=74.36%\n",
      " => Best Thr=0.55, Best Thr Acc=87.73%\n",
      "*** Best Model Saved! val_acc=87.73%, thr=0.55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/12]\n",
      " Train Loss: 0.2416 | Train Acc (0.5 thr): 90.33%\n",
      " Val   Loss: 0.3177\n",
      "   Thr=0.30 | Val Acc=87.48%\n",
      "   Thr=0.35 | Val Acc=87.36%\n",
      "   Thr=0.40 | Val Acc=88.10%\n",
      "   Thr=0.45 | Val Acc=88.59%\n",
      "   Thr=0.50 | Val Acc=89.94%\n",
      "   Thr=0.55 | Val Acc=89.33%\n",
      "   Thr=0.60 | Val Acc=87.98%\n",
      "   Thr=0.65 | Val Acc=84.05%\n",
      "   Thr=0.70 | Val Acc=78.77%\n",
      " => Best Thr=0.50, Best Thr Acc=89.94%\n",
      "*** Best Model Saved! val_acc=89.94%, thr=0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/12]\n",
      " Train Loss: 0.2201 | Train Acc (0.5 thr): 91.80%\n",
      " Val   Loss: 0.2661\n",
      "   Thr=0.30 | Val Acc=90.92%\n",
      "   Thr=0.35 | Val Acc=92.02%\n",
      "   Thr=0.40 | Val Acc=92.52%\n",
      "   Thr=0.45 | Val Acc=92.76%\n",
      "   Thr=0.50 | Val Acc=92.39%\n",
      "   Thr=0.55 | Val Acc=91.17%\n",
      "   Thr=0.60 | Val Acc=90.55%\n",
      "   Thr=0.65 | Val Acc=88.34%\n",
      "   Thr=0.70 | Val Acc=82.09%\n",
      " => Best Thr=0.45, Best Thr Acc=92.76%\n",
      "*** Best Model Saved! val_acc=92.76%, thr=0.45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/12]\n",
      " Train Loss: 0.1920 | Train Acc (0.5 thr): 92.86%\n",
      " Val   Loss: 0.2263\n",
      "   Thr=0.30 | Val Acc=91.04%\n",
      "   Thr=0.35 | Val Acc=91.53%\n",
      "   Thr=0.40 | Val Acc=92.02%\n",
      "   Thr=0.45 | Val Acc=92.64%\n",
      "   Thr=0.50 | Val Acc=93.01%\n",
      "   Thr=0.55 | Val Acc=94.23%\n",
      "   Thr=0.60 | Val Acc=93.87%\n",
      "   Thr=0.65 | Val Acc=93.50%\n",
      "   Thr=0.70 | Val Acc=92.02%\n",
      " => Best Thr=0.55, Best Thr Acc=94.23%\n",
      "*** Best Model Saved! val_acc=94.23%, thr=0.55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/12]\n",
      " Train Loss: 0.1642 | Train Acc (0.5 thr): 94.01%\n",
      " Val   Loss: 0.2075\n",
      "   Thr=0.30 | Val Acc=91.66%\n",
      "   Thr=0.35 | Val Acc=92.27%\n",
      "   Thr=0.40 | Val Acc=92.27%\n",
      "   Thr=0.45 | Val Acc=92.64%\n",
      "   Thr=0.50 | Val Acc=93.01%\n",
      "   Thr=0.55 | Val Acc=93.37%\n",
      "   Thr=0.60 | Val Acc=94.11%\n",
      "   Thr=0.65 | Val Acc=94.36%\n",
      "   Thr=0.70 | Val Acc=94.23%\n",
      " => Best Thr=0.65, Best Thr Acc=94.36%\n",
      "*** Best Model Saved! val_acc=94.36%, thr=0.65\n",
      "\n",
      "Training Completed! Best Val Acc=94.36%, Threshold=0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586072/2049076197.py:353: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"best_model.pth\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Best Model: val_acc=94.36%, thr=0.65\n",
      "Test inference completed. Saved results to 'solution.csv'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Mixed Precision\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# =====================\n",
    "# DistilBERT (HF)\n",
    "# =====================\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# =====================\n",
    "# PARAMS\n",
    "# =====================\n",
    "MAX_LEN = 128\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-5\n",
    "#LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 12  # 예시\n",
    "THRESHOLDS = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 1) Dataset\n",
    "# =====================\n",
    "class Multimodal(Dataset):\n",
    "    \"\"\"\n",
    "    CSV 컬럼 예시: id, img, label, text\n",
    "      - id: 샘플 id\n",
    "      - img: 경로 (e.g. \"train/xxxx.png\")\n",
    "      - label: 0 or 1 (Train/Val) / Test에서는 사용 안 할 수도 있음\n",
    "      - text: \"문장\"\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, img_base_path, is_test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): CSV 파일 경로\n",
    "            img_base_path (str): 이미지가 위치한 상위 폴더 경로\n",
    "            is_test (bool): test 셋일 때 True (label 없는 경우도 고려)\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_base_path = img_base_path\n",
    "        self.is_test = is_test\n",
    "\n",
    "        # DistilBERT 토크나이저\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "        # 이미지 전처리\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(IMG_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std =[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        # --- ID\n",
    "        sample_id = row['id']\n",
    "\n",
    "        # --- Image\n",
    "        img_path = os.path.join(self.img_base_path, row['img'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        # --- Text\n",
    "        text_str = str(row['text'])\n",
    "        encoding = self.tokenizer(\n",
    "            text_str,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze(0)         # shape: (MAX_LEN,)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "        # --- Label (Train/Val 경우)\n",
    "        if not self.is_test:\n",
    "            # label이 있는 경우 float으로\n",
    "            label = torch.tensor(row['label'], dtype=torch.float)\n",
    "        else:\n",
    "            # test 셋이면 label이 없거나 dummy일 수 있음\n",
    "            label = torch.tensor(0.0)\n",
    "\n",
    "        return {\n",
    "            'id': sample_id,\n",
    "            'image': image,\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 2) Model\n",
    "# =====================\n",
    "class MultimodalClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    이미지 인코더: EfficientNet-B0 (pretrained)\n",
    "      - 마지막 분류 레이어 제거 -> 1280 차원 특징 추출\n",
    "    텍스트 인코더: DistilBertModel (pretrained)\n",
    "      - [CLS] 토큰 임베딩 (768차원)\n",
    "    결합: (1280 + 768) → Linear 블록 → 출력 1 (이진분류)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MultimodalClassifier, self).__init__()\n",
    "        # (1) EfficientNet-B0\n",
    "        self.image_encoder = models.efficientnet_b0(pretrained=True)\n",
    "        #   - classifier 부분을 날려서 feature만 추출\n",
    "        self.image_encoder.classifier = nn.Identity()  # (B, 1280)\n",
    "\n",
    "        # (2) DistilBERT\n",
    "        self.text_encoder = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "        # (3) Classifier (concatenate -> linear)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1280 + 768, 512),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(p=0.5)\n",
    "            nn.Dropout(p=0.8),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(p=0.3)\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(64, 1)  # 1차원 로짓 (binary)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        # (a) Image features\n",
    "        img_features = self.image_encoder(images)  # (B,1280)\n",
    "\n",
    "        # (b) Text features\n",
    "        text_outputs = self.text_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        # DistilBertModel: last_hidden_state shape (B, seq_len, hidden_dim=768)\n",
    "        # [CLS] 토큰 = hidden_state[:,0,:]\n",
    "        text_features = text_outputs.last_hidden_state[:, 0, :]  # (B,768)\n",
    "\n",
    "        # (c) Concat\n",
    "        combined = torch.cat((img_features, text_features), dim=1)  # (B, 2048)\n",
    "\n",
    "        # (d) Classifier\n",
    "        logits = self.classifier(combined)  # (B,1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 3) Train Function\n",
    "# =====================\n",
    "def train_model(model, train_loader, val_loader, num_epochs=NUM_EPOCHS):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "\n",
    "    scaler = GradScaler()  # Mixed precision\n",
    "    best_val_acc = 0.0\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ----------\n",
    "        # Training\n",
    "        # ----------\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)  # (B,) float\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                logits = model(images, input_ids, attention_mask)  # (B,1)\n",
    "                loss = criterion(logits.squeeze(), labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            with torch.no_grad():\n",
    "                # 기본 threshold=0.5로 train set accuracy 대략 체크\n",
    "                preds = (torch.sigmoid(logits.squeeze()) >= 0.5).float()\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # ----------\n",
    "        # Validation\n",
    "        #    여러 threshold 시도\n",
    "        # ----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        # logits/labels 모아서 threshold별 accuracy를 한번에 계산\n",
    "        val_logits_list = []\n",
    "        val_labels_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(device)\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                out_logits = model(images, input_ids, attention_mask)  # (B,1)\n",
    "                loss = criterion(out_logits.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_logits_list.append(out_logits.squeeze().cpu())\n",
    "                val_labels_list.append(labels.cpu())\n",
    "\n",
    "        val_logits_tensor = torch.cat(val_logits_list, dim=0)   # (N,)\n",
    "        val_labels_tensor = torch.cat(val_labels_list, dim=0)   # (N,)\n",
    "\n",
    "        # threshold 별 accuracy 측정\n",
    "        threshold_accuracies = {}\n",
    "        for th in THRESHOLDS:\n",
    "            preds = (torch.sigmoid(val_logits_tensor) >= th).float()\n",
    "            correct_count = (preds == val_labels_tensor).sum().item()\n",
    "            acc = 100.0 * correct_count / len(val_labels_tensor)\n",
    "            threshold_accuracies[th] = acc\n",
    "\n",
    "        # 가장 높은 accuracy와 threshold 찾기\n",
    "        best_th, best_th_acc = max(threshold_accuracies.items(), key=lambda x: x[1])\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # 스케줄러 업데이트 (기준: best_th_acc)\n",
    "        scheduler.step(best_th_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\" Train Loss: {avg_train_loss:.4f} | Train Acc (0.5 thr): {train_acc:.2f}%\")\n",
    "        print(f\" Val   Loss: {avg_val_loss:.4f}\")\n",
    "        for th in sorted(THRESHOLDS):\n",
    "            print(f\"   Thr={th:.2f} | Val Acc={threshold_accuracies[th]:.2f}%\")\n",
    "        print(f\" => Best Thr={best_th:.2f}, Best Thr Acc={best_th_acc:.2f}%\")\n",
    "\n",
    "        # Best Model Save\n",
    "        if best_th_acc > best_val_acc:\n",
    "            best_val_acc = best_th_acc\n",
    "            best_threshold = best_th\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'best_threshold': best_threshold\n",
    "            }\n",
    "            torch.save(checkpoint, \"best_model.pth\")\n",
    "            print(f\"*** Best Model Saved! val_acc={best_val_acc:.2f}%, thr={best_threshold:.2f}\\n\")\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Training Completed! Best Val Acc={best_val_acc:.2f}%, Threshold={best_threshold:.2f}\")\n",
    "    return best_val_acc, best_threshold\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 4) Test Inference\n",
    "# =====================\n",
    "def predict_testset(model, test_csv, img_base_path, threshold, out_csv=\"solution.csv\"):\n",
    "    \"\"\"\n",
    "    1) Load test dataset\n",
    "    2) Use the best model & threshold for prediction\n",
    "    3) Save results as csv (id, label)\n",
    "       - label은 0 또는 1\n",
    "    \"\"\"\n",
    "    test_dataset = Multimodal(test_csv, img_base_path, is_test=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    ids_list = []\n",
    "    preds_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            sample_ids = batch['id']\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            logits = model(images, input_ids, attention_mask)  # (B,1)\n",
    "            proba = torch.sigmoid(logits.squeeze())            # (B,)\n",
    "\n",
    "            preds = (proba >= threshold).long().cpu()          # 0 or 1\n",
    "            # 저장\n",
    "            for s_id, pred_label in zip(sample_ids, preds):\n",
    "                ids_list.append(s_id.item())   # id가 int 형식일 경우\n",
    "                preds_list.append(pred_label.item())\n",
    "\n",
    "    # CSV로 저장\n",
    "    df_out = pd.DataFrame({\"id\": ids_list, \"label\": preds_list})\n",
    "    df_out.to_csv(out_csv, index=False)\n",
    "    print(f\"Test inference completed. Saved results to '{out_csv}'\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 5) main (실행 예시)\n",
    "# =====================\n",
    "def main():\n",
    "    # CSV 경로 예시\n",
    "    train_csv = \"osai-project/train_text_label_1.csv\"\n",
    "    val_csv   = \"osai-project/val_text_label.csv\"\n",
    "    test_csv  = \"osai-project/test_text_label.csv\"  # 최종 예측용\n",
    "    img_base_path = \"osai-project\"                  # 실제로는 \"osai-project/train\" 등으로 구성 가능\n",
    "\n",
    "    # (1) 전체 Train+Val 데이터셋 로딩\n",
    "    #     여기서는 예시로 별도 CSV가 있다면 각각 Dataset을 만듦\n",
    "    train_dataset = Multimodal(train_csv, img_base_path, is_test=False)\n",
    "    val_dataset   = Multimodal(val_csv,   img_base_path, is_test=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    # (2) 모델 생성\n",
    "    model = MultimodalClassifier()\n",
    "\n",
    "    # (3) 학습\n",
    "    best_val_acc, best_threshold = train_model(model, train_loader, val_loader, num_epochs=NUM_EPOCHS)\n",
    "\n",
    "    # (4) Best 모델 & Threshold 불러오기\n",
    "    checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    best_threshold = checkpoint[\"best_threshold\"]\n",
    "\n",
    "    print(f\"\\nLoaded Best Model: val_acc={checkpoint['best_val_acc']:.2f}%, thr={best_threshold:.2f}\")\n",
    "\n",
    "    # (5) Test 예측\n",
    "    predict_testset(model, test_csv, img_base_path, threshold=best_threshold, out_csv=\"solution.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/envs/env1/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/anaconda3/envs/env1/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/anaconda3/envs/env1/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1586072/2186319196.py:178: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # Mixed precision\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1586072/2186319196.py:197: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12]\n",
      " Train Loss: 0.6472 | Train Acc (0.5 thr): 63.42%\n",
      " Val   Loss: 0.6502\n",
      "   Thr=0.30 | Val Acc=55.30%\n",
      "   Thr=0.35 | Val Acc=58.51%\n",
      "   Thr=0.40 | Val Acc=61.02%\n",
      "   Thr=0.45 | Val Acc=62.08%\n",
      "   Thr=0.50 | Val Acc=63.09%\n",
      "   Thr=0.55 | Val Acc=63.90%\n",
      "   Thr=0.60 | Val Acc=62.34%\n",
      "   Thr=0.65 | Val Acc=62.34%\n",
      "   Thr=0.70 | Val Acc=62.34%\n",
      " => Best Thr=0.55, Best Thr Acc=63.90%\n",
      "*** Best Model Saved! val_acc=63.90%, thr=0.55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/12]\n",
      " Train Loss: 0.5616 | Train Acc (0.5 thr): 74.41%\n",
      " Val   Loss: 0.6538\n",
      "   Thr=0.30 | Val Acc=61.96%\n",
      "   Thr=0.35 | Val Acc=64.28%\n",
      "   Thr=0.40 | Val Acc=64.72%\n",
      "   Thr=0.45 | Val Acc=64.03%\n",
      "   Thr=0.50 | Val Acc=63.47%\n",
      "   Thr=0.55 | Val Acc=63.84%\n",
      "   Thr=0.60 | Val Acc=64.28%\n",
      "   Thr=0.65 | Val Acc=63.84%\n",
      "   Thr=0.70 | Val Acc=63.53%\n",
      " => Best Thr=0.40, Best Thr Acc=64.72%\n",
      "*** Best Model Saved! val_acc=64.72%, thr=0.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/12]\n",
      " Train Loss: 0.4977 | Train Acc (0.5 thr): 77.63%\n",
      " Val   Loss: 0.6878\n",
      "   Thr=0.30 | Val Acc=63.34%\n",
      "   Thr=0.35 | Val Acc=64.41%\n",
      "   Thr=0.40 | Val Acc=64.85%\n",
      "   Thr=0.45 | Val Acc=64.72%\n",
      "   Thr=0.50 | Val Acc=65.10%\n",
      "   Thr=0.55 | Val Acc=64.16%\n",
      "   Thr=0.60 | Val Acc=64.22%\n",
      "   Thr=0.65 | Val Acc=64.22%\n",
      "   Thr=0.70 | Val Acc=63.84%\n",
      " => Best Thr=0.50, Best Thr Acc=65.10%\n",
      "*** Best Model Saved! val_acc=65.10%, thr=0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/12]\n",
      " Train Loss: 0.4461 | Train Acc (0.5 thr): 80.96%\n",
      " Val   Loss: 0.6531\n",
      "   Thr=0.30 | Val Acc=61.08%\n",
      "   Thr=0.35 | Val Acc=62.59%\n",
      "   Thr=0.40 | Val Acc=63.28%\n",
      "   Thr=0.45 | Val Acc=64.85%\n",
      "   Thr=0.50 | Val Acc=64.09%\n",
      "   Thr=0.55 | Val Acc=65.03%\n",
      "   Thr=0.60 | Val Acc=64.53%\n",
      "   Thr=0.65 | Val Acc=63.72%\n",
      "   Thr=0.70 | Val Acc=63.47%\n",
      " => Best Thr=0.55, Best Thr Acc=65.03%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/12]\n",
      " Train Loss: 0.3948 | Train Acc (0.5 thr): 82.83%\n",
      " Val   Loss: 0.6914\n",
      "   Thr=0.30 | Val Acc=63.03%\n",
      "   Thr=0.35 | Val Acc=64.03%\n",
      "   Thr=0.40 | Val Acc=64.28%\n",
      "   Thr=0.45 | Val Acc=64.72%\n",
      "   Thr=0.50 | Val Acc=64.60%\n",
      "   Thr=0.55 | Val Acc=65.66%\n",
      "   Thr=0.60 | Val Acc=64.85%\n",
      "   Thr=0.65 | Val Acc=64.85%\n",
      "   Thr=0.70 | Val Acc=64.09%\n",
      " => Best Thr=0.55, Best Thr Acc=65.66%\n",
      "*** Best Model Saved! val_acc=65.66%, thr=0.55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/12]\n",
      " Train Loss: 0.3552 | Train Acc (0.5 thr): 84.95%\n",
      " Val   Loss: 0.7027\n",
      "   Thr=0.30 | Val Acc=63.34%\n",
      "   Thr=0.35 | Val Acc=64.72%\n",
      "   Thr=0.40 | Val Acc=66.23%\n",
      "   Thr=0.45 | Val Acc=65.10%\n",
      "   Thr=0.50 | Val Acc=65.47%\n",
      "   Thr=0.55 | Val Acc=66.23%\n",
      "   Thr=0.60 | Val Acc=65.29%\n",
      "   Thr=0.65 | Val Acc=64.47%\n",
      "   Thr=0.70 | Val Acc=64.60%\n",
      " => Best Thr=0.40, Best Thr Acc=66.23%\n",
      "*** Best Model Saved! val_acc=66.23%, thr=0.40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/12]\n",
      " Train Loss: 0.3065 | Train Acc (0.5 thr): 87.04%\n",
      " Val   Loss: 0.7446\n",
      "   Thr=0.30 | Val Acc=64.72%\n",
      "   Thr=0.35 | Val Acc=65.47%\n",
      "   Thr=0.40 | Val Acc=66.16%\n",
      "   Thr=0.45 | Val Acc=66.48%\n",
      "   Thr=0.50 | Val Acc=67.55%\n",
      "   Thr=0.55 | Val Acc=67.42%\n",
      "   Thr=0.60 | Val Acc=66.60%\n",
      "   Thr=0.65 | Val Acc=65.91%\n",
      "   Thr=0.70 | Val Acc=64.47%\n",
      " => Best Thr=0.50, Best Thr Acc=67.55%\n",
      "*** Best Model Saved! val_acc=67.55%, thr=0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/12]\n",
      " Train Loss: 0.2746 | Train Acc (0.5 thr): 88.64%\n",
      " Val   Loss: 0.7345\n",
      "   Thr=0.30 | Val Acc=64.53%\n",
      "   Thr=0.35 | Val Acc=66.35%\n",
      "   Thr=0.40 | Val Acc=67.48%\n",
      "   Thr=0.45 | Val Acc=67.98%\n",
      "   Thr=0.50 | Val Acc=69.37%\n",
      "   Thr=0.55 | Val Acc=69.05%\n",
      "   Thr=0.60 | Val Acc=67.86%\n",
      "   Thr=0.65 | Val Acc=66.23%\n",
      "   Thr=0.70 | Val Acc=64.78%\n",
      " => Best Thr=0.50, Best Thr Acc=69.37%\n",
      "*** Best Model Saved! val_acc=69.37%, thr=0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/12]\n",
      " Train Loss: 0.2391 | Train Acc (0.5 thr): 90.74%\n",
      " Val   Loss: 0.7584\n",
      "   Thr=0.30 | Val Acc=63.59%\n",
      "   Thr=0.35 | Val Acc=64.72%\n",
      "   Thr=0.40 | Val Acc=66.04%\n",
      "   Thr=0.45 | Val Acc=67.29%\n",
      "   Thr=0.50 | Val Acc=68.80%\n",
      "   Thr=0.55 | Val Acc=69.55%\n",
      "   Thr=0.60 | Val Acc=69.93%\n",
      "   Thr=0.65 | Val Acc=69.68%\n",
      "   Thr=0.70 | Val Acc=68.05%\n",
      " => Best Thr=0.60, Best Thr Acc=69.93%\n",
      "*** Best Model Saved! val_acc=69.93%, thr=0.60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/12]\n",
      " Train Loss: 0.2075 | Train Acc (0.5 thr): 92.01%\n",
      " Val   Loss: 0.7705\n",
      "   Thr=0.30 | Val Acc=66.23%\n",
      "   Thr=0.35 | Val Acc=66.67%\n",
      "   Thr=0.40 | Val Acc=68.30%\n",
      "   Thr=0.45 | Val Acc=69.24%\n",
      "   Thr=0.50 | Val Acc=70.24%\n",
      "   Thr=0.55 | Val Acc=70.87%\n",
      "   Thr=0.60 | Val Acc=71.37%\n",
      "   Thr=0.65 | Val Acc=71.50%\n",
      "   Thr=0.70 | Val Acc=68.11%\n",
      " => Best Thr=0.65, Best Thr Acc=71.50%\n",
      "*** Best Model Saved! val_acc=71.50%, thr=0.65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/12]\n",
      " Train Loss: 0.1835 | Train Acc (0.5 thr): 93.13%\n",
      " Val   Loss: 0.8838\n",
      "   Thr=0.30 | Val Acc=66.35%\n",
      "   Thr=0.35 | Val Acc=67.04%\n",
      "   Thr=0.40 | Val Acc=67.92%\n",
      "   Thr=0.45 | Val Acc=68.55%\n",
      "   Thr=0.50 | Val Acc=69.11%\n",
      "   Thr=0.55 | Val Acc=69.99%\n",
      "   Thr=0.60 | Val Acc=71.56%\n",
      "   Thr=0.65 | Val Acc=72.19%\n",
      "   Thr=0.70 | Val Acc=72.07%\n",
      " => Best Thr=0.65, Best Thr Acc=72.19%\n",
      "*** Best Model Saved! val_acc=72.19%, thr=0.65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/12]\n",
      " Train Loss: 0.1633 | Train Acc (0.5 thr): 93.90%\n",
      " Val   Loss: 0.9128\n",
      "   Thr=0.30 | Val Acc=66.42%\n",
      "   Thr=0.35 | Val Acc=67.80%\n",
      "   Thr=0.40 | Val Acc=68.17%\n",
      "   Thr=0.45 | Val Acc=69.11%\n",
      "   Thr=0.50 | Val Acc=69.49%\n",
      "   Thr=0.55 | Val Acc=70.18%\n",
      "   Thr=0.60 | Val Acc=70.75%\n",
      "   Thr=0.65 | Val Acc=71.37%\n",
      "   Thr=0.70 | Val Acc=71.94%\n",
      " => Best Thr=0.70, Best Thr Acc=71.94%\n",
      "\n",
      "Training Completed! Best Val Acc=72.19%, Threshold=0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586072/2186319196.py:353: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"best_model.pth\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Best Model: val_acc=72.19%, thr=0.65\n",
      "Test inference completed. Saved results to 'solution.csv'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Mixed Precision\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# =====================\n",
    "# DistilBERT (HF)\n",
    "# =====================\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# =====================\n",
    "# PARAMS\n",
    "# =====================\n",
    "MAX_LEN = 128\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-5\n",
    "#LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 12  # 예시\n",
    "THRESHOLDS = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 1) Dataset\n",
    "# =====================\n",
    "class Multimodal(Dataset):\n",
    "    \"\"\"\n",
    "    CSV 컬럼 예시: id, img, label, text\n",
    "      - id: 샘플 id\n",
    "      - img: 경로 (e.g. \"train/xxxx.png\")\n",
    "      - label: 0 or 1 (Train/Val) / Test에서는 사용 안 할 수도 있음\n",
    "      - text: \"문장\"\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, img_base_path, is_test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): CSV 파일 경로\n",
    "            img_base_path (str): 이미지가 위치한 상위 폴더 경로\n",
    "            is_test (bool): test 셋일 때 True (label 없는 경우도 고려)\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_base_path = img_base_path\n",
    "        self.is_test = is_test\n",
    "\n",
    "        # DistilBERT 토크나이저\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "        # 이미지 전처리\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(IMG_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std =[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        # --- ID\n",
    "        sample_id = row['id']\n",
    "\n",
    "        # --- Image\n",
    "        img_path = os.path.join(self.img_base_path, row['img'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        # --- Text\n",
    "        text_str = str(row['text'])\n",
    "        encoding = self.tokenizer(\n",
    "            text_str,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze(0)         # shape: (MAX_LEN,)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "        # --- Label (Train/Val 경우)\n",
    "        if not self.is_test:\n",
    "            # label이 있는 경우 float으로\n",
    "            label = torch.tensor(row['label'], dtype=torch.float)\n",
    "        else:\n",
    "            # test 셋이면 label이 없거나 dummy일 수 있음\n",
    "            label = torch.tensor(0.0)\n",
    "\n",
    "        return {\n",
    "            'id': sample_id,\n",
    "            'image': image,\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 2) Model\n",
    "# =====================\n",
    "class MultimodalClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    이미지 인코더: EfficientNet-B0 (pretrained)\n",
    "      - 마지막 분류 레이어 제거 -> 1280 차원 특징 추출\n",
    "    텍스트 인코더: DistilBertModel (pretrained)\n",
    "      - [CLS] 토큰 임베딩 (768차원)\n",
    "    결합: (1280 + 768) → Linear 블록 → 출력 1 (이진분류)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MultimodalClassifier, self).__init__()\n",
    "        # (1) EfficientNet-B0\n",
    "        self.image_encoder = models.efficientnet_b0(pretrained=True)\n",
    "        #   - classifier 부분을 날려서 feature만 추출\n",
    "        self.image_encoder.classifier = nn.Identity()  # (B, 1280)\n",
    "\n",
    "        # (2) DistilBERT\n",
    "        self.text_encoder = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "        # (3) Classifier (concatenate -> linear)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1280 + 768, 512),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(p=0.5)\n",
    "            nn.Dropout(p=0.8),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(p=0.3)\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(64, 1)  # 1차원 로짓 (binary)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        # (a) Image features\n",
    "        img_features = self.image_encoder(images)  # (B,1280)\n",
    "\n",
    "        # (b) Text features\n",
    "        text_outputs = self.text_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        # DistilBertModel: last_hidden_state shape (B, seq_len, hidden_dim=768)\n",
    "        # [CLS] 토큰 = hidden_state[:,0,:]\n",
    "        text_features = text_outputs.last_hidden_state[:, 0, :]  # (B,768)\n",
    "\n",
    "        # (c) Concat\n",
    "        combined = torch.cat((img_features, text_features), dim=1)  # (B, 2048)\n",
    "\n",
    "        # (d) Classifier\n",
    "        logits = self.classifier(combined)  # (B,1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 3) Train Function\n",
    "# =====================\n",
    "def train_model(model, train_loader, val_loader, num_epochs=NUM_EPOCHS):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "\n",
    "    scaler = GradScaler()  # Mixed precision\n",
    "    best_val_acc = 0.0\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ----------\n",
    "        # Training\n",
    "        # ----------\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)  # (B,) float\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                logits = model(images, input_ids, attention_mask)  # (B,1)\n",
    "                loss = criterion(logits.squeeze(), labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            with torch.no_grad():\n",
    "                # 기본 threshold=0.5로 train set accuracy 대략 체크\n",
    "                preds = (torch.sigmoid(logits.squeeze()) >= 0.5).float()\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # ----------\n",
    "        # Validation\n",
    "        #    여러 threshold 시도\n",
    "        # ----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        # logits/labels 모아서 threshold별 accuracy를 한번에 계산\n",
    "        val_logits_list = []\n",
    "        val_labels_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(device)\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                out_logits = model(images, input_ids, attention_mask)  # (B,1)\n",
    "                loss = criterion(out_logits.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_logits_list.append(out_logits.squeeze().cpu())\n",
    "                val_labels_list.append(labels.cpu())\n",
    "\n",
    "        val_logits_tensor = torch.cat(val_logits_list, dim=0)   # (N,)\n",
    "        val_labels_tensor = torch.cat(val_labels_list, dim=0)   # (N,)\n",
    "\n",
    "        # threshold 별 accuracy 측정\n",
    "        threshold_accuracies = {}\n",
    "        for th in THRESHOLDS:\n",
    "            preds = (torch.sigmoid(val_logits_tensor) >= th).float()\n",
    "            correct_count = (preds == val_labels_tensor).sum().item()\n",
    "            acc = 100.0 * correct_count / len(val_labels_tensor)\n",
    "            threshold_accuracies[th] = acc\n",
    "\n",
    "        # 가장 높은 accuracy와 threshold 찾기\n",
    "        best_th, best_th_acc = max(threshold_accuracies.items(), key=lambda x: x[1])\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # 스케줄러 업데이트 (기준: best_th_acc)\n",
    "        scheduler.step(best_th_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\" Train Loss: {avg_train_loss:.4f} | Train Acc (0.5 thr): {train_acc:.2f}%\")\n",
    "        print(f\" Val   Loss: {avg_val_loss:.4f}\")\n",
    "        for th in sorted(THRESHOLDS):\n",
    "            print(f\"   Thr={th:.2f} | Val Acc={threshold_accuracies[th]:.2f}%\")\n",
    "        print(f\" => Best Thr={best_th:.2f}, Best Thr Acc={best_th_acc:.2f}%\")\n",
    "\n",
    "        # Best Model Save\n",
    "        if best_th_acc > best_val_acc:\n",
    "            best_val_acc = best_th_acc\n",
    "            best_threshold = best_th\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'best_threshold': best_threshold\n",
    "            }\n",
    "            torch.save(checkpoint, \"best_model.pth\")\n",
    "            print(f\"*** Best Model Saved! val_acc={best_val_acc:.2f}%, thr={best_threshold:.2f}\\n\")\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Training Completed! Best Val Acc={best_val_acc:.2f}%, Threshold={best_threshold:.2f}\")\n",
    "    return best_val_acc, best_threshold\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 4) Test Inference\n",
    "# =====================\n",
    "def predict_testset(model, test_csv, img_base_path, threshold, out_csv=\"solution.csv\"):\n",
    "    \"\"\"\n",
    "    1) Load test dataset\n",
    "    2) Use the best model & threshold for prediction\n",
    "    3) Save results as csv (id, label)\n",
    "       - label은 0 또는 1\n",
    "    \"\"\"\n",
    "    test_dataset = Multimodal(test_csv, img_base_path, is_test=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    ids_list = []\n",
    "    preds_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            sample_ids = batch['id']\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            logits = model(images, input_ids, attention_mask)  # (B,1)\n",
    "            proba = torch.sigmoid(logits.squeeze())            # (B,)\n",
    "\n",
    "            preds = (proba >= threshold).long().cpu()          # 0 or 1\n",
    "            # 저장\n",
    "            for s_id, pred_label in zip(sample_ids, preds):\n",
    "                ids_list.append(s_id.item())   # id가 int 형식일 경우\n",
    "                preds_list.append(pred_label.item())\n",
    "\n",
    "    # CSV로 저장\n",
    "    df_out = pd.DataFrame({\"id\": ids_list, \"label\": preds_list})\n",
    "    df_out.to_csv(out_csv, index=False)\n",
    "    print(f\"Test inference completed. Saved results to '{out_csv}'\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 5) main (실행 예시)\n",
    "# =====================\n",
    "def main():\n",
    "    # CSV 경로 예시\n",
    "    train_csv = \"osai-project/train_text_label_1.csv\"\n",
    "    val_csv   = \"osai-project/test_text_label_1.csv\"\n",
    "    test_csv  = \"osai-project/test_text_label_1.csv\"  # 최종 예측용\n",
    "    img_base_path = \"osai-project\"                  # 실제로는 \"osai-project/train\" 등으로 구성 가능\n",
    "\n",
    "    # (1) 전체 Train+Val 데이터셋 로딩\n",
    "    #     여기서는 예시로 별도 CSV가 있다면 각각 Dataset을 만듦\n",
    "    train_dataset = Multimodal(train_csv, img_base_path, is_test=False)\n",
    "    val_dataset   = Multimodal(val_csv,   img_base_path, is_test=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    # (2) 모델 생성\n",
    "    model = MultimodalClassifier()\n",
    "\n",
    "    # (3) 학습\n",
    "    best_val_acc, best_threshold = train_model(model, train_loader, val_loader, num_epochs=NUM_EPOCHS)\n",
    "\n",
    "    # (4) Best 모델 & Threshold 불러오기\n",
    "    checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    best_threshold = checkpoint[\"best_threshold\"]\n",
    "\n",
    "    print(f\"\\nLoaded Best Model: val_acc={checkpoint['best_val_acc']:.2f}%, thr={best_threshold:.2f}\")\n",
    "\n",
    "    # (5) Test 예측\n",
    "    predict_testset(model, test_csv, img_base_path, threshold=best_threshold, out_csv=\"solution.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
